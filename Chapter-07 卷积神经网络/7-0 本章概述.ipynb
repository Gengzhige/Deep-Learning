{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 本章概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面三章，我们从浅层的线性神经网络讲起，介绍了深度的非线性神经网络，然后又详细介绍了求解深度网络模型的梯度下降法及其各种变体。从神经网络的发展史来看，这些工作早在七八十年前就已经完成了，感知机模型1950年就被Frank Rosenblatt提出来了，但是由于其自身的各种问题和没有计算机能够实现这种网络，所以这项工作没有得到进一步的发展。直到在 1980 年代，神经网络技术开始被广泛应用于各种领域，如自然语言处理、图像识别。那么在 1980 年代之后，神经网络技术又发生了哪些变化呢？本章开始，梗直哥就带你深入了解其中一类最重要的模型：卷积神经网络。\n",
    "\n",
    "卷积神经网络是人类识别、自动驾驶汽车等大多数计算机视觉应用的支柱。可以认为是一种特殊的神经网络架构，其中基本的矩阵乘法运算被卷积运算取代，专门处理具有网格状拓扑结构的数据。卷积神经网络于1980年由Fukushima首次提出，叫做Neocognitron。灵感来自 Hubel 和 Weisel 提出的神经系统层次模型。最初该模型并不流行，因为其复杂的无监督学习算法被称为没有老师的学习。Yann LeCun 在 1989 年使用反向传播和Neocognitron的概念提出了一种名为LeNet的架构，被美国邮政服务用于手写邮政编码识别。Yann LeCun坚持不懈，不断改进这个模型，最终在 1998 年发布了 LeNet-5，第一个引入了我们今天仍在 CNN 中使用的一些基本概念的现代卷积神经网络。同时，他还发布了 MNIST 手写数字数据集，这可能是机器学习中最著名的基准数据集。在上世纪90年代，计算机视觉领域转移了重心，神经网络研究经历了一个寒冬，直到 2012 年，多伦多大学的一组研究人员在著名的 ImageNet 挑战赛中使用基于 CNN 的模型（AlexNet），以 16.4% 的错误率获胜受到学术界和工业界的热烈关注，由此也引发了人工智能新的春天。\n",
    "\n",
    "让我们一起来深入了解这类明显模型的原理和技术细节吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next 7-1 卷积层](./7-1%20卷积层.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
